{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xView Vehicle Object Detection Data Prep\n",
    "\n",
    "This notebook prepares data for training an object detection model on the xView dataset.\n",
    "\n",
    "Once you have downloaded the training images and labels from the xView competition site, you must unzip them and put the contents of each zipfile in an s3 bucket that you have read/write access to. Provide the uri to this bucket in the cell below. This is the only thing you will need to do in order to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/opt/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps we'll take to prepare the data are as follows:\n",
    "\n",
    "- Download the xView object detection labels from s3\n",
    "- Filter out all of the non-vehicle bounding boxes from the labels. Combine all vehicle types into one class. \n",
    "- Subset the entire xView dataset to only include the images that are most densely populated with vehicles.\n",
    "- Split the selected images randomly into 80%/20% training and validation sets\n",
    "- Split the vehicle labels by image, save off a label GeoJSON file per image, and upload to S3\n",
    "\n",
    "\n",
    "This process will save off of the split labels to S3, and save off a `train_scenes.csv` and `val_scenes.csv` that is used by the experiment at `xview.object_detection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the xView label data from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = '/opt/data/xview/labels/xView_train.geojson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out non-vehicle labels\n",
    "\n",
    "The xView dataset includes labels for a number of different types of objects. We are only interested in building a detector for objects that can be categorized as vehicles (e.g. 'small car', 'passenger vehicle', 'bus'). We have pre-determined the ids that map to vehicle labels and will use them to extract all the vehicles from the whole xView label set. In this section we also assign a class name of 'vehicle' to all of the resulting labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_type_ids = [17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 32, \n",
    "                    53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_js = None\n",
    "with open(label_path) as f:\n",
    "    label_js = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_features = []\n",
    "for f in label_js['features']:\n",
    "    if f['properties']['type_id'] in vehicle_type_ids:\n",
    "        f['properties']['class_name'] = 'vehicle'\n",
    "        vehicle_features.append(f)\n",
    "label_js['features'] = vehicle_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset images with the most vehicles\n",
    "\n",
    "In this section we determine which images contain the most vehicles and are therefor the best candidates for this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_vehicle_counts = {}\n",
    "for f in label_js['features']:\n",
    "    image_id = f['properties']['image_id']\n",
    "    if image_id not in image_to_vehicle_counts.keys():\n",
    "        image_to_vehicle_counts[image_id] = 1\n",
    "    else:\n",
    "        image_to_vehicle_counts[image_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_image_count = round(len(image_to_vehicle_counts.keys()) * 0.1)\n",
    "sorted_images_and_counts = sorted(image_to_vehicle_counts.items(), key=lambda x: x[1])\n",
    "selected_images_and_counts = sorted_images_and_counts[-experiment_image_count:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and validation\n",
    "\n",
    "Split up training and validation data. Use 80% of images in the training set and 20% in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_image_count  74\n",
      "training_sample_size  59\n",
      "train_sample  [45, 14, 54, 46, 35, 12, 22, 34, 5, 68, 36, 61, 71, 69, 18, 57, 8, 29, 30, 60, 25, 2, 24, 10, 4, 7, 44, 11, 28, 23, 0, 43, 58, 73, 66, 55, 62, 13, 27, 3, 42, 15, 47, 26, 50, 16, 41, 70, 53, 21, 52, 40, 17, 33, 1, 32, 31, 67, 56]\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.8\n",
    "training_sample_size = round(ratio * experiment_image_count)\n",
    "train_sample = random.sample(range(experiment_image_count), training_sample_size)\n",
    "\n",
    "train_images = []\n",
    "test_images = []\n",
    "print(\"experiment_image_count \", experiment_image_count)\n",
    "print(\"training_sample_size \", training_sample_size)\n",
    "print(\"train_sample \", train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(training_sample_size):\n",
    "    img = selected_images_and_counts[i][0]\n",
    "    img_uri = os.path.join(base_dir, 'train_images', img)\n",
    "    if i in train_sample:\n",
    "        train_images.append(img_uri)\n",
    "    else:\n",
    "        test_images.append(img_uri)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide labels up by image\n",
    "\n",
    "Using one vehicle label geojson for all of the training and test images can become unwieldy. Instead, we will divide the labels up so that each image has a unique geojson associated with it. We will save off each of these geojsons and upload the base s3 directory you provided at the outset.\n",
    "\n",
    "Create a CSV that our experiments will use to load up the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_labels_dir = '/opt/data/xview/processed_labels/'\n",
    "if not os.path.exists(processed_labels_dir):\n",
    "    os.makedirs(processed_labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def subset_labels(tiff_list, processed_labels_dir):\n",
    "    def f(tiff_uri):\n",
    "        tiff_basename = os.path.basename(tiff_uri)\n",
    "        tiff_features = []\n",
    "        for l in label_js['features']:\n",
    "            image_id = l['properties']['image_id']\n",
    "            if image_id == tiff_basename:\n",
    "                tiff_features.append(l)\n",
    "        labels_subset = {}\n",
    "        for key in label_js:\n",
    "            if not key == 'features':\n",
    "                labels_subset[key] = label_js[key]\n",
    "        labels_subset['features'] = tiff_features\n",
    "        return labels_subset \n",
    "    \n",
    "    for i in train_images:\n",
    "        basename = os.path.splitext(os.path.basename(i))[0]\n",
    "        tiff_geojson = f(i)\n",
    "        with open(os.path.join(processed_labels_dir, '{}.geojson'.format(basename)), 'w') as file:\n",
    "            file.write(json.dumps(tiff_geojson, indent=4))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_labels(train_images, processed_labels_dir)\n",
    "subset_labels(test_images, processed_labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(images, csv_name):\n",
    "    csv_rows = []\n",
    "    for img in images:\n",
    "        basename = os.path.splitext(os.path.basename(img))[0]\n",
    "        labels_path = os.path.join(base_dir,'{}.geojson'.format(basename))\n",
    "        csv_rows.append('\"{}\",\"{}\"'.format(img, labels_path))\n",
    "    with open('/opt/data/xview/{}.csv'.format(csv_name), 'w') as f:\n",
    "        f.write('\\n'.join(csv_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv(train_images, 'training_scenes')\n",
    "create_csv(test_images, 'val_scenes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
